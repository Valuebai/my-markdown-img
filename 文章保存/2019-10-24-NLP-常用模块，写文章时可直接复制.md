---
title: 2019-10-24-NLP-常用模块，写文章时可直接复制
tags: python,
author:  Valuebai
---

本实验Python代码的实现使用到了多个著名的第三方模块，主要模块如下所示：

（1）Jieba
目前使用最为广泛的中文分词组件。下载地址：https://pypi.python.org/pypi/jieba/

（2）Gensim
用于主题模型、文档索引和大型语料相似度索引的python库，主要用于自然语言处理（NLP）和信息检索（IR）。下载地址：https://pypi.python.org/pypi/gensim

本实例中的维基中文语料处理和中文词向量模型构建需要用到该模块。

（3）Pandas
用于高效处理大型数据集、执行数据分析任务的python库，是基于Numpy的工具包。

下载地址：https://pypi.python.org/pypi/pandas/0.20.1

（4）Numpy
用于存储和处理大型矩阵的工具包。

下载地址：https://pypi.python.org/pypi/numpy

（5）Scikit-learn
用于机器学习的python工具包，python模块引用名字为sklearn，安装前还需要Numpy和Scipy两个Python库。

官网地址：http://scikit-learn.org/stable/

本实例中主要用到了该模块中的feature_extraction、KMeans（k-means聚类算法）和PCA（pac降维算法）。

（6）Matplotlib
Matplotlib是一个python的图形框架，用于绘制二维图形。

下载地址：https://pypi.python.org/pypi/matplotlib


【Me】https://github.com/Valuebai/

【参考】
1、出处：地址