---
title: 2019-11-15-NLP-[译]Pandas常用命令对照清单
tags: python,
author:  Valuebai
---


在做python数据分析、NLP自然语言处理的数据清洗，常常需要使用pandas、numpy对加载的数据进行处理，本文翻译了国外的panda命令行清单总结记录下。
主要包括：pandas导入/导出数据、创建测试对象、 查看数据、数据选择、数据清洗、过滤，排序和分组、数据连接、数学统计...


- 本文内容中使用以下简写：
> df ：任一pandas的DataFrame对象，Any pandas DataFrame object
> s ：pandas的Series对象，Any pandas Series object


- 导入以下包开始
> import pandas as pd  # 导入pandas库并简写为pd
> import numpy as np  # 导入numpy库并简写为np


## 导入数据
```python
pd.read_csv(filename) 从csv导入
pd.read_table(filename) 从分隔的文本文件导入
pd.read_excel(filename) 从excel文件导入
pd.read_sql(query, connection_object) 从SQL数据库读取
pd.read_json(json_string) 读取json格式的字符串、URL或文件
pd.read_html(url) 解析html的url，字符串或者文件，从一系列的dataframes提取table
pd.read_clipboard() 获取剪切板的内容，将其传递给read_table
pd.DataFrame(dict) 从dict获取DataFrame，键名为栏目名，值为一系列的列表

```


## 导出数据
```python
df.to_csv(filename) 写入csv文件
df.to_excel(filename) 写入excel文件
df.to_sql(table_name, connection_object) 写入SQL数据库(表)
df.to_json(filename) 以json文件的形式写入
df.to_html(filename) 保存成html格式
df.to_clipboard() 写进剪贴板

```

## 创建测试对象
```python
pd.DataFrame(np.random.rand(20,5)) 生成5列20行的随机浮点数
pd.Series(my_list) 用可迭代列表创造一列数据
df.index = pd.date_range('1900/1/30',periods=df.shape[0]) 增加一个日期索引

```

## 查看数据
```python
df.head(n) DataFrame开头的n行记录，df.head()是默认前5行的数据
df.tail(n) DataFrame结尾的n行记录
df.shape() DataFrame行、列数
df.info() 展示Index,行列数据长度、类型、Datatype,Memory相关信息
df.describe() 数字列的相关综合统计，#describe()函数只能显示数值型的数据统计，如float64能统计，object不统计
s.value_counts(dropna=False) 查看某一列唯一的值并统计数量
df.apply(pd.Series.value_counts) 查看所有的列唯一的值并统计数量

```


## 数据选择
```python
df[col] 取出标签是col的一列
df[[col1, col2]] 作为DataFrame返回两列
s.iloc[0] 根据位置选择  
s.loc[0] 根据索引选择
df.iloc[0,:] 第一行
df.iloc[0,0] 第一列的第一个元素

```

## 数据清洗
```python
df.columns = ['a','b','c']重命名列
pd.isnull() 确认是否为空值，返回布尔数组
pd.notnull() 与上面相反
df.dropna() 删除所有包含null值的行记录
df.dropna(axis=1) 删除所有包含null值的列记录
df.dropna(axis=1,thresh=n) 删除所有包含少于n个非空值的行
df.fillna(s.mean()) 用平均值替换掉所有空值
s.astype(float) 将某series的数据转换成float的数据类型　
s.replace(1,'one') 将所有值等于１的替换为one
s.replace([1,3], ['one','three']) 将所有值等于１的替换为one,3替换为three
df.rename(columns=lambda x:x+1)　取上一般性的标题名
df.rename(columns={'old_name':'new_name'}) 指定列名重命名
df.set_index('column_one')　修改索引

```



## 过滤，排序和分组
```python
df[df[col] > 0.5] col列值大于0.5的行
df[(df[col] >0.5) & (df[col] <0.7)] col列值大于0.5小于0.7的行
df.sort_values(col1) 按照col1进行升序进行排列
df.sort_values(col2,ascending=False) 根据col2进行降序排列
df.sort_values([col1,col2],ascending=[True,False]) 根据col1升序col2降序联合排列
df.groupby(col) 根据某列的值返回分组对象
df.groupby([col1,col2]) 根据多列的值返回分组对象
df.groupby(col1)[col2].mean() 根据col1值返回分组对象，求col2列的平均值
df.pivot_table(index=col1,values=[col2,col3],aggfunc=mean) 
创建一个按col1分组的数据透视表，并计算col2和col3的平均值
df.groupby(col1).agg(np.mean) 查找每个唯一col1组的所有列的平均值
df.apply(np.mean) 给每一列都计算平均值
df.apply(np.max, axis=1) 找出每一行的最大值

```



## 数据连接
```python
df1.append(df2) 将df1的数据添加在df2下方(列必须相同) ——kaggle老师经验告诉我，得用append()，而不用concat，有坑就是了
df.concat([df1,df2],axis=1) 将df2的数据加载df1右侧(行必须相同)
df1.join(df2,on=col1,how='inner')SQL的方式加入列df1与列在df2其中对于行col具有相同的值。how参数可以为'left'，'right'，'outer'，'inner'

```


## 数学统计
```python
df.describe() 显示总体统计的汇总状况
df.mean() 返回所有列的平均值
df.corr() 返回Dataframe列之间的相关关系
df.count() 返回Dataframe列中的非空值数量
df.max() 返回Dataframe列中的最大值
df.min() 返回Dataframe列中的最低值
df.median() 返回Dataframe每列的中位数
df.std() 返回Dataframe每列的标准差

```






【Me】https://github.com/Valuebai/

【参考】
1、Pandas Cheat Sheet — Python for Data Science：https://www.dataquest.io/blog/pandas-cheat-sheet/